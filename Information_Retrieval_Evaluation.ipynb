{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Information Retrieval Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBm7WyzGkuGgRLzE74fmYf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadyadtm/Document-Retrieval/blob/main/Information_Retrieval_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gz07ZNPHJc2"
      },
      "source": [
        "# Information Retrieval Evaluation\n",
        "Berikut ini adalah evaluasi dari information retrieval mengenai data COVID 19 dengan menggunakan Sentence BERT dan TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FnwecAG9uHP"
      },
      "source": [
        "## Load Data dan Import Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt4Zi_Cv0D2v",
        "outputId": "c4ea7a97-da75-4239-85be-0c8f697aeeb7"
      },
      "source": [
        "# Menginstall Sentence-Transformers\n",
        "!pip install sentence-transformers"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: transformers<5.0.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.5.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.95)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.1+cu101)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.10.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.10.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.44)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWIge6dchu0L",
        "outputId": "25f3574b-9a9d-4354-9daa-3c418dfd227e"
      },
      "source": [
        "!wget 'https://raw.githubusercontent.com/deepset-ai/COVID-QA/master/data/question-answering/COVID-QA.json'"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-17 22:10:15--  https://raw.githubusercontent.com/deepset-ai/COVID-QA/master/data/question-answering/COVID-QA.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4418117 (4.2M) [text/plain]\n",
            "Saving to: ‘COVID-QA.json.2’\n",
            "\n",
            "COVID-QA.json.2     100%[===================>]   4.21M  22.4MB/s    in 0.2s    \n",
            "\n",
            "2021-04-17 22:10:16 (22.4 MB/s) - ‘COVID-QA.json.2’ saved [4418117/4418117]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xTPQxwmiJ_o"
      },
      "source": [
        "raw_file = './COVID-QA.json'"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "H6YZIdX0iXn4",
        "outputId": "6f42a4fa-57af-459c-9d6d-eda9ead9fda1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_json(raw_file)\n",
        "data = pd.json_normalize(data['data'], record_path='paragraphs')\n",
        "new_data = pd.DataFrame(0, index=np.arange(2019),columns=[\"document_id\", \"context\", \"id_question\", \"question\", \"answers_start\", \"answers_text\", \"is_impossible\"])\n",
        "idx = 0\n",
        "for x in range(0,len(data['qas'])):\n",
        "  for y in range(0, len(data['qas'][x])):\n",
        "    new_data['document_id'].iloc[idx]=data['document_id'][x]\n",
        "    new_data['context'].iloc[idx]=data['context'][x]\n",
        "    new_data['id_question'].iloc[idx] = data['qas'][x][y]['id']\n",
        "    new_data['question'].iloc[idx] = data['qas'][x][y]['question']\n",
        "    new_data['answers_start'].iloc[idx] = data['qas'][x][y]['answers'][0]['answer_start']\n",
        "    new_data['answers_text'].iloc[idx] = data['qas'][x][y]['answers'][0]['text']\n",
        "    new_data['is_impossible'].iloc[idx] = data['qas'][x][y]['is_impossible']\n",
        "    idx+=1\n",
        "new_data\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>context</th>\n",
              "      <th>id_question</th>\n",
              "      <th>question</th>\n",
              "      <th>answers_start</th>\n",
              "      <th>answers_text</th>\n",
              "      <th>is_impossible</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>630</td>\n",
              "      <td>Functional Genetic Variants in DC-SIGNR Are As...</td>\n",
              "      <td>262</td>\n",
              "      <td>What is the main cause of HIV-1 infection in c...</td>\n",
              "      <td>370</td>\n",
              "      <td>Mother-to-child transmission (MTCT) is the mai...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>630</td>\n",
              "      <td>Functional Genetic Variants in DC-SIGNR Are As...</td>\n",
              "      <td>276</td>\n",
              "      <td>What plays the crucial role in the Mother to C...</td>\n",
              "      <td>2003</td>\n",
              "      <td>DC-SIGNR plays a crucial role in MTCT of HIV-1...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>630</td>\n",
              "      <td>Functional Genetic Variants in DC-SIGNR Are As...</td>\n",
              "      <td>278</td>\n",
              "      <td>How many children were infected by HIV-1 in 20...</td>\n",
              "      <td>2291</td>\n",
              "      <td>more than 400,000 children were infected world...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>630</td>\n",
              "      <td>Functional Genetic Variants in DC-SIGNR Are As...</td>\n",
              "      <td>316</td>\n",
              "      <td>What is the role of C-C Motif Chemokine Ligand...</td>\n",
              "      <td>28143</td>\n",
              "      <td>High copy numbers of CCL3L1, a potent HIV-1 su...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>630</td>\n",
              "      <td>Functional Genetic Variants in DC-SIGNR Are As...</td>\n",
              "      <td>305</td>\n",
              "      <td>What is DC-GENR and where is  it expressed?</td>\n",
              "      <td>3207</td>\n",
              "      <td>Dendritic cell-specific ICAM-grabbing non-inte...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014</th>\n",
              "      <td>1713</td>\n",
              "      <td>Ebola Virus Maintenance: If Not (Only) Bats, W...</td>\n",
              "      <td>5315</td>\n",
              "      <td>What is the structure of the Ebolavirus?</td>\n",
              "      <td>2270</td>\n",
              "      <td>single-strand RNA filoviruses</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015</th>\n",
              "      <td>1713</td>\n",
              "      <td>Ebola Virus Maintenance: If Not (Only) Bats, W...</td>\n",
              "      <td>5316</td>\n",
              "      <td>When was the West African Ebolavirus outbreak?</td>\n",
              "      <td>2546</td>\n",
              "      <td>2013-2016</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016</th>\n",
              "      <td>1713</td>\n",
              "      <td>Ebola Virus Maintenance: If Not (Only) Bats, W...</td>\n",
              "      <td>5317</td>\n",
              "      <td>What animals are considered to be maintenance ...</td>\n",
              "      <td>4083</td>\n",
              "      <td>African bats</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017</th>\n",
              "      <td>1713</td>\n",
              "      <td>Ebola Virus Maintenance: If Not (Only) Bats, W...</td>\n",
              "      <td>5318</td>\n",
              "      <td>What do circles indicate in Figure 1?</td>\n",
              "      <td>7212</td>\n",
              "      <td>a maintenance function play by the host(s)</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018</th>\n",
              "      <td>1713</td>\n",
              "      <td>Ebola Virus Maintenance: If Not (Only) Bats, W...</td>\n",
              "      <td>5319</td>\n",
              "      <td>What do arrows indicate in Figure 1?</td>\n",
              "      <td>7273</td>\n",
              "      <td>infectious transmission pathways between hosts</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2019 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      document_id  ... is_impossible\n",
              "0             630  ...         False\n",
              "1             630  ...         False\n",
              "2             630  ...         False\n",
              "3             630  ...         False\n",
              "4             630  ...         False\n",
              "...           ...  ...           ...\n",
              "2014         1713  ...         False\n",
              "2015         1713  ...         False\n",
              "2016         1713  ...         False\n",
              "2017         1713  ...         False\n",
              "2018         1713  ...         False\n",
              "\n",
              "[2019 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krb0DIwLPRBj"
      },
      "source": [
        "## Mengambil Dokumen yang Tersedia\n",
        "Pada bagian ini, dilakukan pengambilan seluruh dokumen pada dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifPy_8USl9Ce"
      },
      "source": [
        "#ambil context dan question\n",
        "docs_train = new_data[['document_id','context']]"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa8dHxSPYuKk",
        "outputId": "9b5d0396-8b2e-4853-8782-ce05e9a61e9b"
      },
      "source": [
        "docs_train.drop_duplicates(subset=None, keep='first', inplace=True)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkjH8BrtgfA1"
      },
      "source": [
        "## Preprocessing\n",
        "Pada bagian ini dilakukan preprocessing dengan menghilangkan sitasi, link, dan digit, kemudian melakukan lower case, stopword removal, dan lemmatisasi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y50IgvymBZTf",
        "outputId": "008bb3c0-da1b-424e-f8c2-979cb1c6d16a"
      },
      "source": [
        "#package\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import pos_tag\n",
        "\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYo3AZn9Q2Tn"
      },
      "source": [
        "import re\n",
        "def punc_remove(sentence):\n",
        "  punc = re.compile(\"[^\\w\\s]\")\n",
        "  # Regex to check valid URL\n",
        "  regex_link = (\"((http|https)://)(www.)?\" +\n",
        "             \"[a-zA-Z0-9@:%._\\\\+~#?&//=]\" +\n",
        "             \"{2,256}\\\\.[a-z]\" +\n",
        "             \"{2,6}\\\\b([-a-zA-Z0-9@:%\" +\n",
        "             \"._\\\\+~#?&//=]*)\")\n",
        "  citation = (\"(\\[\\d+-\\d+\\]|\\[\\d+(, \\d+)*\\])\")\n",
        "     \n",
        "  # Compile the ReGex\n",
        "  p = re.compile(regex_link)\n",
        "  r = re.compile(citation)\n",
        "  digits = re.compile('[0-9]')\n",
        "\n",
        "\n",
        "  sentence = sentence.replace('\\n',' ')\n",
        "  sentence = p.sub(' ',sentence)\n",
        "  sentence = r.sub(' ',sentence)\n",
        "  test_str = digits.sub(' ',sentence)\n",
        "  test_str = test_str.split(' ')\n",
        "\n",
        "  x = ' '.join(test_str).split()\n",
        "  y = ' '.join(x)\n",
        "\n",
        "  return y\n",
        "  \n",
        "def clean_data(text):\n",
        "  lem = WordNetLemmatizer()\n",
        "  lower_case = text.lower()\n",
        "  tokenized = word_tokenize(lower_case)\n",
        "  data_lemmatize=[lem.lemmatize(word) for word in tokenized if not word in stopwords.words('english')]\n",
        "  data_fixed = ' '.join(data_lemmatize)\n",
        "  return data_fixed"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baoZCvucRR7Q"
      },
      "source": [
        "docs_clean_train = [clean_data(punc_remove(sentence)) for sentence in docs_train['context']]"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwU3UICQVMzb",
        "outputId": "dc7d98e5-170d-4d2d-f318-f9f7b3927ff8"
      },
      "source": [
        "docs_train['cleaned_data'] = docs_clean_train"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02PdLRWnHpsi"
      },
      "source": [
        "## TF IDF Feature\n",
        "Pada modul ini, dilakukan pengambilan fitur TF-IDF dengan max_features 2000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtsb2cCJo5Yn"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyLESqdbqEdF"
      },
      "source": [
        "tfidfvectorizer = TfidfVectorizer(analyzer='word',stop_words= 'english', max_features=2000)\n",
        "fixtrain = tfidfvectorizer.fit_transform(docs_train['cleaned_data']).toarray()"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "nLf8j1jxA-Rj",
        "outputId": "2609497d-5f77-4dcb-edc6-c763f93b6041"
      },
      "source": [
        "import pandas as pd\n",
        "df_tfidf = pd.DataFrame(fixtrain, columns=tfidfvectorizer.get_feature_names())\n",
        "df_tfidf.head(5)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aa</th>\n",
              "      <th>ab</th>\n",
              "      <th>ability</th>\n",
              "      <th>able</th>\n",
              "      <th>absence</th>\n",
              "      <th>abstract</th>\n",
              "      <th>abundance</th>\n",
              "      <th>access</th>\n",
              "      <th>accession</th>\n",
              "      <th>accessory</th>\n",
              "      <th>accordance</th>\n",
              "      <th>according</th>\n",
              "      <th>account</th>\n",
              "      <th>accumulation</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>accurate</th>\n",
              "      <th>ace</th>\n",
              "      <th>achieved</th>\n",
              "      <th>acid</th>\n",
              "      <th>acquired</th>\n",
              "      <th>acquisition</th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>activate</th>\n",
              "      <th>activated</th>\n",
              "      <th>activation</th>\n",
              "      <th>active</th>\n",
              "      <th>activity</th>\n",
              "      <th>acute</th>\n",
              "      <th>ad</th>\n",
              "      <th>adapted</th>\n",
              "      <th>adaptive</th>\n",
              "      <th>added</th>\n",
              "      <th>addition</th>\n",
              "      <th>additional</th>\n",
              "      <th>additionally</th>\n",
              "      <th>address</th>\n",
              "      <th>adenovirus</th>\n",
              "      <th>adg</th>\n",
              "      <th>adhesion</th>\n",
              "      <th>...</th>\n",
              "      <th>washing</th>\n",
              "      <th>water</th>\n",
              "      <th>wave</th>\n",
              "      <th>way</th>\n",
              "      <th>week</th>\n",
              "      <th>weekly</th>\n",
              "      <th>weight</th>\n",
              "      <th>west</th>\n",
              "      <th>western</th>\n",
              "      <th>white</th>\n",
              "      <th>wide</th>\n",
              "      <th>widely</th>\n",
              "      <th>widespread</th>\n",
              "      <th>wild</th>\n",
              "      <th>winter</th>\n",
              "      <th>woman</th>\n",
              "      <th>work</th>\n",
              "      <th>worker</th>\n",
              "      <th>working</th>\n",
              "      <th>world</th>\n",
              "      <th>worldwide</th>\n",
              "      <th>wt</th>\n",
              "      <th>wuhan</th>\n",
              "      <th>www</th>\n",
              "      <th>year</th>\n",
              "      <th>yfp</th>\n",
              "      <th>yield</th>\n",
              "      <th>yn</th>\n",
              "      <th>young</th>\n",
              "      <th>zanamivir</th>\n",
              "      <th>zhang</th>\n",
              "      <th>zinc</th>\n",
              "      <th>zm</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoonotic</th>\n",
              "      <th>µl</th>\n",
              "      <th>µm</th>\n",
              "      <th>μg</th>\n",
              "      <th>μl</th>\n",
              "      <th>μm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.019085</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001578</td>\n",
              "      <td>0.005157</td>\n",
              "      <td>0.003987</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018534</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008691</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003584</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020155</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004207</td>\n",
              "      <td>0.004463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005528</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002897</td>\n",
              "      <td>0.014237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004093</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017535</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004267</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002621</td>\n",
              "      <td>0.006728</td>\n",
              "      <td>0.078216</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004039</td>\n",
              "      <td>0.002300</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001572</td>\n",
              "      <td>0.00296</td>\n",
              "      <td>0.027181</td>\n",
              "      <td>0.000841</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001235</td>\n",
              "      <td>0.003953</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.026258</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024179</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004716</td>\n",
              "      <td>0.011762</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002182</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002947</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001545</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.026186</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014959</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004198</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.048119</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002153</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004999</td>\n",
              "      <td>0.0025</td>\n",
              "      <td>0.007921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.216544</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016696</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.283367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024516</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030130</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.048777</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008809</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.02587</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019374</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023823</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006085</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.044690</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007734</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010981</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015784</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008869</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         aa        ab   ability     able  ...   µm        μg      μl        μm\n",
              "0  0.019085  0.000000  0.000000  0.00000  ...  0.0  0.000000  0.0000  0.000000\n",
              "1  0.000000  0.000000  0.001572  0.00296  ...  0.0  0.004999  0.0025  0.007921\n",
              "2  0.000000  0.216544  0.000000  0.00000  ...  0.0  0.000000  0.0000  0.000000\n",
              "3  0.000000  0.000000  0.000000  0.00000  ...  0.0  0.000000  0.0000  0.000000\n",
              "4  0.000000  0.000000  0.000000  0.00000  ...  0.0  0.000000  0.0000  0.000000\n",
              "\n",
              "[5 rows x 2000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c47ejTLfBBGb",
        "outputId": "399ddb50-c449-4779-c9d4-d6810720bb85"
      },
      "source": [
        "docs_train['vector_tf_idf']=df_tfidf.values.tolist()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "8YDDCCUcEXVS",
        "outputId": "4ad93b8f-f5f3-43cf-bbf2-badbe5f384b2"
      },
      "source": [
        "docs_train.head()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>context</th>\n",
              "      <th>cleaned_data</th>\n",
              "      <th>vector_tf_idf</th>\n",
              "      <th>vector_bert</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>630</td>\n",
              "      <td>Functional Genetic Variants in DC-SIGNR Are As...</td>\n",
              "      <td>functional genetic variant dc-signr associated...</td>\n",
              "      <td>[0.019085058375148987, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "      <td>[-0.3364379405975342, 0.5945848226547241, -0.3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>650</td>\n",
              "      <td>Role of S-Palmitoylation on IFITM5 for the Int...</td>\n",
              "      <td>role s-palmitoylation ifitm interaction fkbp o...</td>\n",
              "      <td>[0.0, 0.0, 0.0015718760321186836, 0.0029601433...</td>\n",
              "      <td>[-0.4851241707801819, 0.05968009680509567, 0.5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1546</td>\n",
              "      <td>First Complete Genome Sequence of a French Bov...</td>\n",
              "      <td>first complete genome sequence french bovine c...</td>\n",
              "      <td>[0.0, 0.21654350686727633, 0.0, 0.0, 0.0, 0.01...</td>\n",
              "      <td>[-0.4597166180610657, 0.5825439095497131, -0.5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1545</td>\n",
              "      <td>Species‐specific clinical characteristics of h...</td>\n",
              "      <td>species‐specific clinical characteristic human...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.008809309160605168...</td>\n",
              "      <td>[-0.25380608439445496, 0.8041989803314209, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>1552</td>\n",
              "      <td>One step closer to an experimental infection s...</td>\n",
              "      <td>one step closer experimental infection system ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.006085110520319744...</td>\n",
              "      <td>[-0.25736328959465027, 0.6820797324180603, 0.5...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    document_id  ...                                        vector_bert\n",
              "0           630  ...  [-0.3364379405975342, 0.5945848226547241, -0.3...\n",
              "11          650  ...  [-0.4851241707801819, 0.05968009680509567, 0.5...\n",
              "22         1546  ...  [-0.4597166180610657, 0.5825439095497131, -0.5...\n",
              "27         1545  ...  [-0.25380608439445496, 0.8041989803314209, -0....\n",
              "34         1552  ...  [-0.25736328959465027, 0.6820797324180603, 0.5...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTSYIZuMHkm_"
      },
      "source": [
        "## Sentence Bert Model\n",
        "Pada modul ini, dilakukan embedding dengan model Sentence BERT dengan arsitektur pre-trained bert-base-nli-mean-tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFGZgoJoWl2J"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load the BERT model. Various models trained on Natural Language Inference (NLI) https://github.com/UKPLab/sentence-transformers/blob/master/docs/pretrained-models/nli-models.md and \n",
        "# Semantic Textual Similarity are available https://github.com/UKPLab/sentence-transformers/blob/master/docs/pretrained-models/sts-models.md\n",
        "\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyI9HINQp7-B"
      },
      "source": [
        "def sentence_embeddings(docs):\n",
        "  sentence_embeddings = model.encode(docs)\n",
        "  return sentence_embeddings"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ_Pp8SeqjhN"
      },
      "source": [
        "x=sentence_embeddings(docs_train['cleaned_data'].to_list())"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T83MJUvWzVum",
        "outputId": "58e31b68-ebab-4e34-bbaa-a9e3c82466a6"
      },
      "source": [
        "x[0].shape"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yFCPTisvGyS",
        "outputId": "f4440e55-4e1e-4de0-b6a9-6f9146968e81"
      },
      "source": [
        "y=pd.DataFrame(x)\n",
        "docs_train['vector_bert']=y.values.tolist()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo59IQPrWIXI"
      },
      "source": [
        "## Similarity\n",
        "Kemudian dibuat fungsi similarity untuk kedua kasus, yaitu ranking_ir_bert() dan ranking_ir_tf_idf. Kemudian akan diambil 10 dokumen terbaik berdasarkan similarity terbesar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-nvCFoVNsVG"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHC6uZreNISe"
      },
      "source": [
        "def ranking_ir_bert(query):\n",
        "\n",
        "  query = clean_data(punc_remove(query))\n",
        "\n",
        "  # mengenerate vektor\n",
        "  vector=sentence_embeddings([query])\n",
        "  \n",
        "  # perankingan dokumen dengan cosine similarity\n",
        "  documents=docs_train.copy()\n",
        "  documents['similarity']=documents['vector_bert'].apply(lambda x: cosine_similarity(np.array(vector).reshape(1, -1),np.array(x).reshape(1, -1)).item())\n",
        "  documents.sort_values(by='similarity',ascending=False,inplace=True)\n",
        "  \n",
        "  return documents[['document_id','context','similarity']].head(10).reset_index(drop=True)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_Gq-rQTIIoU"
      },
      "source": [
        "def ranking_ir_tf_idf(query):\n",
        "\n",
        "  query = clean_data(punc_remove(query))\n",
        "\n",
        "  # mengenerate vektor\n",
        "  vector=tfidfvectorizer.transform([query]).toarray()\n",
        "  \n",
        "  # perankingan dokumen dengan cosine similarity\n",
        "  documents=docs_train.copy()\n",
        "  documents['similarity']=documents['vector_tf_idf'].apply(lambda x: cosine_similarity(np.array(vector).reshape(1, -1),np.array(x).reshape(1, -1)).item())\n",
        "  documents.sort_values(by='similarity',ascending=False,inplace=True)\n",
        "  \n",
        "  return documents[['document_id','context','similarity']].head(10).reset_index(drop=True)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "TCH_6XUduE8Q",
        "outputId": "908b5d18-244e-40f2-97a8-a6c6c64544cb"
      },
      "source": [
        "ranking_ir_bert('main cause COVID-19')"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>context</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1620</td>\n",
              "      <td>A missense mutation in Katnal1 underlies behav...</td>\n",
              "      <td>0.525459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1565</td>\n",
              "      <td>Design, Synthesis, Evaluation and Thermodynami...</td>\n",
              "      <td>0.467449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1561</td>\n",
              "      <td>Acute Hemorrhagic Encephalitis Responding to C...</td>\n",
              "      <td>0.430197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1629</td>\n",
              "      <td>The Intranasal Application of Zanamivir and Ca...</td>\n",
              "      <td>0.427358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1628</td>\n",
              "      <td>Evidence for the Convergence Model: The Emerge...</td>\n",
              "      <td>0.425695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1600</td>\n",
              "      <td>The influenza pandemic preparedness planning t...</td>\n",
              "      <td>0.424730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2683</td>\n",
              "      <td>Estimating the number of infections and the im...</td>\n",
              "      <td>0.423405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>650</td>\n",
              "      <td>Role of S-Palmitoylation on IFITM5 for the Int...</td>\n",
              "      <td>0.422395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1586</td>\n",
              "      <td>In Vitro Bactericidal Activity of 4- and 5-Chl...</td>\n",
              "      <td>0.414151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1632</td>\n",
              "      <td>Metabolic engineering of Escherichia coli into...</td>\n",
              "      <td>0.408922</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   document_id                                            context  similarity\n",
              "0         1620  A missense mutation in Katnal1 underlies behav...    0.525459\n",
              "1         1565  Design, Synthesis, Evaluation and Thermodynami...    0.467449\n",
              "2         1561  Acute Hemorrhagic Encephalitis Responding to C...    0.430197\n",
              "3         1629  The Intranasal Application of Zanamivir and Ca...    0.427358\n",
              "4         1628  Evidence for the Convergence Model: The Emerge...    0.425695\n",
              "5         1600  The influenza pandemic preparedness planning t...    0.424730\n",
              "6         2683  Estimating the number of infections and the im...    0.423405\n",
              "7          650  Role of S-Palmitoylation on IFITM5 for the Int...    0.422395\n",
              "8         1586  In Vitro Bactericidal Activity of 4- and 5-Chl...    0.414151\n",
              "9         1632  Metabolic engineering of Escherichia coli into...    0.408922"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPV_8uYZ2BqB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "0ac68b8e-394e-492f-b791-f76ec9c8fc0b"
      },
      "source": [
        "ranking_ir_tf_idf('main cause COVID-19')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>context</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>185</td>\n",
              "      <td>CDC Summary 21 MAR 2020,\\nhttps://www.cdc.gov/...</td>\n",
              "      <td>0.557419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2450</td>\n",
              "      <td>Safe patient transport for COVID-19\\n\\nhttps:/...</td>\n",
              "      <td>0.363624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>188</td>\n",
              "      <td>The Battle Against Coronavirus Disease 2019 (C...</td>\n",
              "      <td>0.317647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1559</td>\n",
              "      <td>COVID-19 and smoking: A systematic review of t...</td>\n",
              "      <td>0.248786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2522</td>\n",
              "      <td>Identification of COVID-19 Can be Quicker thro...</td>\n",
              "      <td>0.234826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2432</td>\n",
              "      <td>Factors Associated With Mental Health Outcomes...</td>\n",
              "      <td>0.194040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2642</td>\n",
              "      <td>First cases of coronavirus disease 2019 (COVID...</td>\n",
              "      <td>0.159228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2643</td>\n",
              "      <td>Responding to the COVID-19 pandemic in complex...</td>\n",
              "      <td>0.147440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2440</td>\n",
              "      <td>Optimization Method for Forecasting Confirmed ...</td>\n",
              "      <td>0.135337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2683</td>\n",
              "      <td>Estimating the number of infections and the im...</td>\n",
              "      <td>0.129470</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   document_id                                            context  similarity\n",
              "0          185  CDC Summary 21 MAR 2020,\\nhttps://www.cdc.gov/...    0.557419\n",
              "1         2450  Safe patient transport for COVID-19\\n\\nhttps:/...    0.363624\n",
              "2          188  The Battle Against Coronavirus Disease 2019 (C...    0.317647\n",
              "3         1559  COVID-19 and smoking: A systematic review of t...    0.248786\n",
              "4         2522  Identification of COVID-19 Can be Quicker thro...    0.234826\n",
              "5         2432  Factors Associated With Mental Health Outcomes...    0.194040\n",
              "6         2642  First cases of coronavirus disease 2019 (COVID...    0.159228\n",
              "7         2643  Responding to the COVID-19 pandemic in complex...    0.147440\n",
              "8         2440  Optimization Method for Forecasting Confirmed ...    0.135337\n",
              "9         2683  Estimating the number of infections and the im...    0.129470"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4qbFCRdJRRf"
      },
      "source": [
        "## Pengujian dengan Keyword"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUAK2knfNkdd"
      },
      "source": [
        "### Fungsi Keyword \n",
        "Melakukan pengambilan keyword yang digunakan dalam modul Question "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kizrdb_npRLg"
      },
      "source": [
        "def extract_keyword(postag):\n",
        "  keyword = \"\"\n",
        "  for i in range(0,len(postag)):\n",
        "    if postag[i][1]==\"NNP\" or postag[i][1]==\"NNS\" or postag[i][1]==\"NN\" or (postag[i][1]==\"JJ\" and postag[i][0].lower()!=\"many\") or postag[i][1]==\"CD\" or postag[i][1]==\"RBS\" or (postag[i][1]==\"VBN\" and postag[i][1]!=\"been\") or (postag[i][1]==\"VBD\" and postag[i][0].lower()!=\"was\" and postag[i][0].lower()!=\"were\") or postag[i][1]==\"VBG\" or (postag[i][1]==\"VB\" and postag[i][0].lower()!=\"be\") or postag[i][1]==\"RB\":\n",
        "      keyword += postag[i][0] +\" \"\n",
        "  if len(keyword)!=0 and keyword[len(keyword)-1] == \" \":\n",
        "    keyword = keyword[:-1]\n",
        "  return keyword"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mqwam11rcyH"
      },
      "source": [
        "def question_type_extraction(question):\n",
        "  qarray = [0,0,0,0,0,0,0,0,0]\n",
        "  labq = [\"What\",\"Where\",\"Why\",\"Who\",\"When\",\"How much\",\"How many\",\"Which\",\"How\"]\n",
        "  qtype = \"\"\n",
        "  what = 0\n",
        "  where = 1\n",
        "  why = 2\n",
        "  who = 3\n",
        "  when = 4\n",
        "  howmuch = 5\n",
        "  howmany = 6\n",
        "  which = 7\n",
        "  how = 8\n",
        "\n",
        "  for i in range(0,len(question)):\n",
        "    if question[i].lower() == \"what\":\n",
        "      qarray[what] = 1\n",
        "    elif question[i].lower() == \"where\":\n",
        "      qarray[where] = 1\n",
        "    elif question[i].lower() == \"why\":\n",
        "      qarray[why] = 1\n",
        "    elif question[i].lower() == \"who\":\n",
        "      qarray[who] = 1\n",
        "    elif question[i].lower() == \"when\":\n",
        "      qarray[when] = 1\n",
        "    elif question[i].lower() == \"which\":\n",
        "      qarray[which] = 1\n",
        "    elif question[i].lower() == \"how\":\n",
        "      if question[i+1].lower() != \"much\" and question[i+1].lower() != \"many\":\n",
        "        qarray[how] = 1\n",
        "      elif question[i+1].lower() == \"much\":\n",
        "        qarray[howmuch] = 1\n",
        "      elif question[i+1].lower() == \"many\":\n",
        "        qarray[howmany] = 1\n",
        "\n",
        "  \n",
        "  if 1 in qarray:\n",
        "    for i in range(0,len(qarray)):\n",
        "      if qarray[i]==1:\n",
        "        qtype += labq[i] + \",\"\n",
        "  else:\n",
        "    qtype=\"Unknown\"\n",
        "\n",
        "  if qtype[len(qtype)-1] == \",\":\n",
        "    qtype = qtype[:-1]\n",
        "  return qtype"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzRxxdC7pZzZ"
      },
      "source": [
        " def question_understanding(dataset):\n",
        "  keywords = []\n",
        "  qtype = []\n",
        "  answer = []\n",
        "\n",
        "  for i in range(0,len(dataset)):\n",
        "    sentence = pos_tag(word_tokenize(dataset.question[i]))\n",
        "    keywords.append(extract_keyword(sentence))\n",
        "    qtype.append(question_type_extraction(word_tokenize(dataset.question[i])))\n",
        "    ans = dataset.answers_text[i]\n",
        "    answer.append(ans)\n",
        "  \n",
        "  output = pd.DataFrame({\"keywords\":np.array(keywords),\n",
        "                         \"question_type\":np.array(qtype),\n",
        "                         \"answer\":np.array(answer)})\n",
        "\n",
        "  return output"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jI3P2kFNn3A"
      },
      "source": [
        "### Evaluasi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvHH9_PIatzO"
      },
      "source": [
        "#### TF IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzsTl4HUpnu7"
      },
      "source": [
        "qu = question_understanding(new_data)\n",
        "qu['docs_id']=new_data['document_id']"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykbTEKvpJTKH"
      },
      "source": [
        "qu['docs_recc']=qu['keywords'].apply(lambda x : ranking_ir_tf_idf(x))"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSW9nHn4C9u_"
      },
      "source": [
        "Pada evaluasi ini, dilakukan pengecekan pada masing-masing apakah dokumen dari keyword tersebut termasuk ke dalam 10 dokumen terbaik yang didapat dari keyword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5b42ihaRxGu"
      },
      "source": [
        "is_docs_there=[]\n",
        "for idx,item in qu.iterrows():\n",
        "  is_docs_there.append(item['docs_id'] in qu['docs_recc'][idx]['document_id'].unique())"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyrWsGlzZHoR",
        "outputId": "3206dc69-06d5-4c95-a6eb-a307dc261bde"
      },
      "source": [
        "qu['is_found']=is_docs_there\n",
        "print(qu['is_found'].sum()/2019)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6988608221892025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4z48-fdcn54"
      },
      "source": [
        "Berdasarkan hasil evaluasi, dari 2019 pertanyaan, 69% pertanyaan berhasil mendapatkan dokumen yang sesuai berdasarkan 10 dokumen yang diambil sebelumnya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX4b8YtNax5h"
      },
      "source": [
        "#### BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGr8Hz38ay2f"
      },
      "source": [
        "qu = question_understanding(new_data)\n",
        "qu['docs_id']=new_data['document_id']"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a282g5pWa5eF"
      },
      "source": [
        "qu['docs_recc']=qu['keywords'].apply(lambda x : ranking_ir_bert(x))"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36nRglvzcXtM"
      },
      "source": [
        "Pada evaluasi ini, dilakukan pengecekan pada masing-masing apakah dokumen dari keyword tersebut termasuk ke dalam 10 dokumen terbaik yang didapat dari keyword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQAG_hvtbXN3"
      },
      "source": [
        "is_docs_there=[]\n",
        "for idx,item in qu.iterrows():\n",
        "  is_docs_there.append(item['docs_id'] in qu['docs_recc'][idx]['document_id'].unique())"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3MTcEShbdhy",
        "outputId": "aa2d5300-f35e-49ba-e2ce-42715f708813"
      },
      "source": [
        "qu['is_found']=is_docs_there\n",
        "print(qu['is_found'].sum()/2019)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2555720653789004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaplDqA5dS1e"
      },
      "source": [
        "Berdasarkan hasil evaluasi, dari 2019 pertanyaan, 25% pertanyaan berhasil mendapatkan dokumen yang sesuai berdasarkan 10 dokumen yang diambil sebelumnya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWuS6Xjd6xuy"
      },
      "source": [
        "#### Keyword yang tidak jelas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "259cGMUwEO6P"
      },
      "source": [
        "Pada dataset terdapat keyword yang tidak jelas seperti pada cell dibawah ini, sehingga dokumen yang di retrieve tidak benar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "ckkgdtsh3QFE",
        "outputId": "02cacf5c-03f6-4ffc-af10-53b847ae1dd8"
      },
      "source": [
        "qu.tail(1)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keywords</th>\n",
              "      <th>question_type</th>\n",
              "      <th>answer</th>\n",
              "      <th>docs_id</th>\n",
              "      <th>docs_recc</th>\n",
              "      <th>is_found</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2018</th>\n",
              "      <td>arrows indicate Figure 1</td>\n",
              "      <td>What</td>\n",
              "      <td>infectious transmission pathways between hosts</td>\n",
              "      <td>1713</td>\n",
              "      <td>document_id                                ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      keywords  ... is_found\n",
              "2018  arrows indicate Figure 1  ...    False\n",
              "\n",
              "[1 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "py17p_iE3TLE",
        "outputId": "c7d6e572-6e4a-4fc3-f353-c82a047e2706"
      },
      "source": [
        "ranking_ir_tf_idf(qu.keywords[2018])"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>context</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2683</td>\n",
              "      <td>Estimating the number of infections and the im...</td>\n",
              "      <td>0.064803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2519</td>\n",
              "      <td>Detectable 2019-nCoV viral RNA in blood is a s...</td>\n",
              "      <td>0.064411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>186</td>\n",
              "      <td>Identifying Locations with Possible Undetected...</td>\n",
              "      <td>0.061561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1621</td>\n",
              "      <td>Vesicular stomatitis virus with the rabies vir...</td>\n",
              "      <td>0.051927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1576</td>\n",
              "      <td>Characterization of a New Member of Alphacoron...</td>\n",
              "      <td>0.051283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1698</td>\n",
              "      <td>Accelerated viral dynamics in bat cell lines, ...</td>\n",
              "      <td>0.049541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1662</td>\n",
              "      <td>The Evolutionary Dynamics of the Lion Panthera...</td>\n",
              "      <td>0.049041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1596</td>\n",
              "      <td>Glycyrrhizin Exerts Antioxidative Effects in H...</td>\n",
              "      <td>0.047571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1620</td>\n",
              "      <td>A missense mutation in Katnal1 underlies behav...</td>\n",
              "      <td>0.047453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1585</td>\n",
              "      <td>Immunomodulatory Activity and Protective Effec...</td>\n",
              "      <td>0.042563</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   document_id                                            context  similarity\n",
              "0         2683  Estimating the number of infections and the im...    0.064803\n",
              "1         2519  Detectable 2019-nCoV viral RNA in blood is a s...    0.064411\n",
              "2          186  Identifying Locations with Possible Undetected...    0.061561\n",
              "3         1621  Vesicular stomatitis virus with the rabies vir...    0.051927\n",
              "4         1576  Characterization of a New Member of Alphacoron...    0.051283\n",
              "5         1698  Accelerated viral dynamics in bat cell lines, ...    0.049541\n",
              "6         1662  The Evolutionary Dynamics of the Lion Panthera...    0.049041\n",
              "7         1596  Glycyrrhizin Exerts Antioxidative Effects in H...    0.047571\n",
              "8         1620  A missense mutation in Katnal1 underlies behav...    0.047453\n",
              "9         1585  Immunomodulatory Activity and Protective Effec...    0.042563"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9t_mE7d3heJ"
      },
      "source": [
        ""
      ],
      "execution_count": 108,
      "outputs": []
    }
  ]
}