{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Information Retrieval Evaluation BERT TFIDF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMo70WgxhS+npOLb0JSI6wh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "83e27774769742ba9903fde92eab8ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_493ee653b01c4e7ba52678b6e9a555e7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6bb6eca63a5947faaf246a7527b31757",
              "IPY_MODEL_c3d22af1d546478b9bcea5a8f40ce093"
            ]
          }
        },
        "493ee653b01c4e7ba52678b6e9a555e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6bb6eca63a5947faaf246a7527b31757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fbbe1c591fde431e830120344fc8712f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 405234788,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 405234788,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_499bd2383e2b491db28f085efc67d267"
          }
        },
        "c3d22af1d546478b9bcea5a8f40ce093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_036ffbccfd09409595f0ee5b8302b68d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 405M/405M [00:23&lt;00:00, 17.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0e6ae66d27947749db16a470965e1d2"
          }
        },
        "fbbe1c591fde431e830120344fc8712f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "499bd2383e2b491db28f085efc67d267": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "036ffbccfd09409595f0ee5b8302b68d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0e6ae66d27947749db16a470965e1d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadyadtm/Document-Retrieval/blob/main/Information_Retrieval_Evaluation_BERT_TFIDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gz07ZNPHJc2"
      },
      "source": [
        "# Information Retrieval Evaluation\n",
        "Berikut ini adalah evaluasi dari information retrieval mengenai data COVID 19 dengan menggunakan Sentence BERT dan TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FnwecAG9uHP"
      },
      "source": [
        "## Load Data dan Import Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt4Zi_Cv0D2v",
        "outputId": "a3c10d82-0c77-4eec-b2cb-81bc03cfeb04"
      },
      "source": [
        "# Menginstall Sentence-Transformers\n",
        "!pip install sentence-transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/aa/f672ce489063c4ee7a566ebac1b723c53ac0cea19d9e36599cc241d8ed56/sentence-transformers-1.0.4.tar.gz (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.4MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 24.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 45.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 34.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-1.0.4-cp37-none-any.whl size=114307 sha256=f2bdaf228df0407f3e84534aacf12861486e3d6d05f6b1b473aab07413bcd188\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/ea/89/d0d2e013d951b6d23270aa9ca4018b82632ab7cd933c331316\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=1b9ad64894bcc133b28695c6073ddfaad43174055fc6247fe8407f3bc1623b43\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers, sentencepiece, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.44 sentence-transformers-1.0.4 sentencepiece-0.1.95 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWIge6dchu0L",
        "outputId": "8f483756-4b37-4521-f2c0-2eaf166dc311"
      },
      "source": [
        "!wget 'https://raw.githubusercontent.com/deepset-ai/COVID-QA/master/data/question-answering/COVID-QA.json'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-17 23:35:17--  https://raw.githubusercontent.com/deepset-ai/COVID-QA/master/data/question-answering/COVID-QA.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4418117 (4.2M) [text/plain]\n",
            "Saving to: ‘COVID-QA.json’\n",
            "\n",
            "\rCOVID-QA.json         0%[                    ]       0  --.-KB/s               \rCOVID-QA.json       100%[===================>]   4.21M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-04-17 23:35:17 (77.3 MB/s) - ‘COVID-QA.json’ saved [4418117/4418117]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xTPQxwmiJ_o"
      },
      "source": [
        "raw_file = './COVID-QA.json'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "H6YZIdX0iXn4",
        "outputId": "27494505-6867-48a2-b268-a78326b2c484"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_json(raw_file)\n",
        "data = pd.json_normalize(data['data'], record_path='paragraphs')\n",
        "new_data = pd.DataFrame(0, index=np.arange(2019),columns=[\"document_id\", \"context\", \"id_question\", \"question\", \"answers_start\", \"answers_text\", \"is_impossible\"])\n",
        "idx = 0\n",
        "for x in range(0,len(data['qas'])):\n",
        "  for y in range(0, len(data['qas'][x])):\n",
        "    new_data['document_id'].iloc[idx]=data['document_id'][x]\n",
        "    new_data['context'].iloc[idx]=data['context'][x]\n",
        "    new_data['id_question'].iloc[idx] = data['qas'][x][y]['id']\n",
        "    new_data['question'].iloc[idx] = data['qas'][x][y]['question']\n",
        "    new_data['answers_start'].iloc[idx] = data['qas'][x][y]['answers'][0]['answer_start']\n",
        "    new_data['answers_text'].iloc[idx] = data['qas'][x][y]['answers'][0]['text']\n",
        "    new_data['is_impossible'].iloc[idx] = data['qas'][x][y]['is_impossible']\n",
        "    idx+=1\n",
        "new_data\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>context</th>\n",
              "      <th>id_question</th>\n",
              "      <th>question</th>\n",
              "      <th>answers_start</th>\n",
              "      <th>answers_text</th>\n",
              "      <th>is_impossible</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>630</td>\n",
              "      <td>Functional Genetic Variants in DC-SIGNR Are As...</td>\n",
              "      <td>262</td>\n",
              "      <td>What is the main cause of HIV-1 infection in c...</td>\n",
              "      <td>370</td>\n",
              "      <td>Mother-to-child transmission (MTCT) is the mai...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>630</td>\n",
              "      <td>Functional Genetic Variants in DC-SIGNR Are As...</td>\n",
              "      <td>276</td>\n",
              "      <td>What plays the crucial role in the Mother to C...</td>\n",
              "      <td>2003</td>\n",
              "      <td>DC-SIGNR plays a crucial role in MTCT of HIV-1...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>630</td>\n",
              "      <td>Functional Genetic Variants in DC-SIGNR Are As...</td>\n",
              "      <td>278</td>\n",
              "      <td>How many children were infected by HIV-1 in 20...</td>\n",
              "      <td>2291</td>\n",
              "      <td>more than 400,000 children were infected world...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>630</td>\n",
              "      <td>Functional Genetic Variants in DC-SIGNR Are As...</td>\n",
              "      <td>316</td>\n",
              "      <td>What is the role of C-C Motif Chemokine Ligand...</td>\n",
              "      <td>28143</td>\n",
              "      <td>High copy numbers of CCL3L1, a potent HIV-1 su...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>630</td>\n",
              "      <td>Functional Genetic Variants in DC-SIGNR Are As...</td>\n",
              "      <td>305</td>\n",
              "      <td>What is DC-GENR and where is  it expressed?</td>\n",
              "      <td>3207</td>\n",
              "      <td>Dendritic cell-specific ICAM-grabbing non-inte...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014</th>\n",
              "      <td>1713</td>\n",
              "      <td>Ebola Virus Maintenance: If Not (Only) Bats, W...</td>\n",
              "      <td>5315</td>\n",
              "      <td>What is the structure of the Ebolavirus?</td>\n",
              "      <td>2270</td>\n",
              "      <td>single-strand RNA filoviruses</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015</th>\n",
              "      <td>1713</td>\n",
              "      <td>Ebola Virus Maintenance: If Not (Only) Bats, W...</td>\n",
              "      <td>5316</td>\n",
              "      <td>When was the West African Ebolavirus outbreak?</td>\n",
              "      <td>2546</td>\n",
              "      <td>2013-2016</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016</th>\n",
              "      <td>1713</td>\n",
              "      <td>Ebola Virus Maintenance: If Not (Only) Bats, W...</td>\n",
              "      <td>5317</td>\n",
              "      <td>What animals are considered to be maintenance ...</td>\n",
              "      <td>4083</td>\n",
              "      <td>African bats</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017</th>\n",
              "      <td>1713</td>\n",
              "      <td>Ebola Virus Maintenance: If Not (Only) Bats, W...</td>\n",
              "      <td>5318</td>\n",
              "      <td>What do circles indicate in Figure 1?</td>\n",
              "      <td>7212</td>\n",
              "      <td>a maintenance function play by the host(s)</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018</th>\n",
              "      <td>1713</td>\n",
              "      <td>Ebola Virus Maintenance: If Not (Only) Bats, W...</td>\n",
              "      <td>5319</td>\n",
              "      <td>What do arrows indicate in Figure 1?</td>\n",
              "      <td>7273</td>\n",
              "      <td>infectious transmission pathways between hosts</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2019 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      document_id  ... is_impossible\n",
              "0             630  ...         False\n",
              "1             630  ...         False\n",
              "2             630  ...         False\n",
              "3             630  ...         False\n",
              "4             630  ...         False\n",
              "...           ...  ...           ...\n",
              "2014         1713  ...         False\n",
              "2015         1713  ...         False\n",
              "2016         1713  ...         False\n",
              "2017         1713  ...         False\n",
              "2018         1713  ...         False\n",
              "\n",
              "[2019 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krb0DIwLPRBj"
      },
      "source": [
        "## Mengambil Dokumen yang Tersedia\n",
        "Pada bagian ini, dilakukan pengambilan seluruh dokumen pada dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifPy_8USl9Ce"
      },
      "source": [
        "#ambil context dan question\n",
        "docs_train = new_data[['document_id','context']]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa8dHxSPYuKk",
        "outputId": "62367cd6-d6bb-4105-8f07-cb4f03e4abb1"
      },
      "source": [
        "docs_train.drop_duplicates(subset=None, keep='first', inplace=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkjH8BrtgfA1"
      },
      "source": [
        "## Preprocessing\n",
        "Pada bagian ini dilakukan preprocessing dengan menghilangkan sitasi, link, dan digit, kemudian melakukan lower case, stopword removal, dan lemmatisasi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y50IgvymBZTf",
        "outputId": "66a44b54-1255-4af4-b824-971b9f7f86d1"
      },
      "source": [
        "#package\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import pos_tag\n",
        "\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYo3AZn9Q2Tn"
      },
      "source": [
        "import re\n",
        "def punc_remove(sentence):\n",
        "  punc = re.compile(\"[^\\w\\s]\")\n",
        "  # Regex to check valid URL\n",
        "  regex_link = (\"((http|https)://)(www.)?\" +\n",
        "             \"[a-zA-Z0-9@:%._\\\\+~#?&//=]\" +\n",
        "             \"{2,256}\\\\.[a-z]\" +\n",
        "             \"{2,6}\\\\b([-a-zA-Z0-9@:%\" +\n",
        "             \"._\\\\+~#?&//=]*)\")\n",
        "  citation = (\"(\\[\\d+-\\d+\\]|\\[\\d+(, \\d+)*\\])\")\n",
        "     \n",
        "  # Compile the ReGex\n",
        "  p = re.compile(regex_link)\n",
        "  r = re.compile(citation)\n",
        "  digits = re.compile('[0-9]')\n",
        "\n",
        "\n",
        "  sentence = sentence.replace('\\n',' ')\n",
        "  sentence = p.sub(' ',sentence)\n",
        "  sentence = r.sub(' ',sentence)\n",
        "  test_str = digits.sub(' ',sentence)\n",
        "  test_str = test_str.split(' ')\n",
        "\n",
        "  x = ' '.join(test_str).split()\n",
        "  y = ' '.join(x)\n",
        "\n",
        "  return y\n",
        "  \n",
        "def clean_data(text):\n",
        "  lem = WordNetLemmatizer()\n",
        "  lower_case = text.lower()\n",
        "  tokenized = word_tokenize(lower_case)\n",
        "  data_lemmatize=[lem.lemmatize(word) for word in tokenized if not word in stopwords.words('english')]\n",
        "  data_fixed = ' '.join(data_lemmatize)\n",
        "  return data_fixed"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baoZCvucRR7Q"
      },
      "source": [
        "docs_clean_train = [clean_data(punc_remove(sentence)) for sentence in docs_train['context']]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwU3UICQVMzb",
        "outputId": "49c1a8d6-a4fa-40d1-9344-cd4ed9131848"
      },
      "source": [
        "docs_train['cleaned_data'] = docs_clean_train"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02PdLRWnHpsi"
      },
      "source": [
        "## TF IDF Feature\n",
        "Pada modul ini, dilakukan pengambilan fitur TF-IDF dengan max_features 2000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtsb2cCJo5Yn"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyLESqdbqEdF"
      },
      "source": [
        "tfidfvectorizer = TfidfVectorizer(analyzer='word',stop_words= 'english', max_features=2000)\n",
        "fixtrain = tfidfvectorizer.fit_transform(docs_train['cleaned_data']).toarray()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "nLf8j1jxA-Rj",
        "outputId": "6925ef4e-dc4d-41e4-f9b1-d7d56b8a2d34"
      },
      "source": [
        "import pandas as pd\n",
        "df_tfidf = pd.DataFrame(fixtrain, columns=tfidfvectorizer.get_feature_names())\n",
        "df_tfidf.head(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aa</th>\n",
              "      <th>ab</th>\n",
              "      <th>ability</th>\n",
              "      <th>able</th>\n",
              "      <th>absence</th>\n",
              "      <th>abstract</th>\n",
              "      <th>abundance</th>\n",
              "      <th>access</th>\n",
              "      <th>accession</th>\n",
              "      <th>accessory</th>\n",
              "      <th>accordance</th>\n",
              "      <th>according</th>\n",
              "      <th>account</th>\n",
              "      <th>accumulation</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>accurate</th>\n",
              "      <th>ace</th>\n",
              "      <th>achieved</th>\n",
              "      <th>acid</th>\n",
              "      <th>acquired</th>\n",
              "      <th>acquisition</th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>activate</th>\n",
              "      <th>activated</th>\n",
              "      <th>activation</th>\n",
              "      <th>active</th>\n",
              "      <th>activity</th>\n",
              "      <th>acute</th>\n",
              "      <th>ad</th>\n",
              "      <th>adapted</th>\n",
              "      <th>adaptive</th>\n",
              "      <th>added</th>\n",
              "      <th>addition</th>\n",
              "      <th>additional</th>\n",
              "      <th>additionally</th>\n",
              "      <th>address</th>\n",
              "      <th>adenovirus</th>\n",
              "      <th>adg</th>\n",
              "      <th>adhesion</th>\n",
              "      <th>...</th>\n",
              "      <th>washing</th>\n",
              "      <th>water</th>\n",
              "      <th>wave</th>\n",
              "      <th>way</th>\n",
              "      <th>week</th>\n",
              "      <th>weekly</th>\n",
              "      <th>weight</th>\n",
              "      <th>west</th>\n",
              "      <th>western</th>\n",
              "      <th>white</th>\n",
              "      <th>wide</th>\n",
              "      <th>widely</th>\n",
              "      <th>widespread</th>\n",
              "      <th>wild</th>\n",
              "      <th>winter</th>\n",
              "      <th>woman</th>\n",
              "      <th>work</th>\n",
              "      <th>worker</th>\n",
              "      <th>working</th>\n",
              "      <th>world</th>\n",
              "      <th>worldwide</th>\n",
              "      <th>wt</th>\n",
              "      <th>wuhan</th>\n",
              "      <th>www</th>\n",
              "      <th>year</th>\n",
              "      <th>yfp</th>\n",
              "      <th>yield</th>\n",
              "      <th>yn</th>\n",
              "      <th>young</th>\n",
              "      <th>zanamivir</th>\n",
              "      <th>zhang</th>\n",
              "      <th>zinc</th>\n",
              "      <th>zm</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoonotic</th>\n",
              "      <th>µl</th>\n",
              "      <th>µm</th>\n",
              "      <th>μg</th>\n",
              "      <th>μl</th>\n",
              "      <th>μm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.019085</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001578</td>\n",
              "      <td>0.005157</td>\n",
              "      <td>0.003987</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018534</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008691</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003584</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020155</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004207</td>\n",
              "      <td>0.004463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005528</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002897</td>\n",
              "      <td>0.014237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004093</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017535</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004267</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002621</td>\n",
              "      <td>0.006728</td>\n",
              "      <td>0.078216</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004039</td>\n",
              "      <td>0.002300</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001572</td>\n",
              "      <td>0.00296</td>\n",
              "      <td>0.027181</td>\n",
              "      <td>0.000841</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001235</td>\n",
              "      <td>0.003953</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.026258</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024179</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004716</td>\n",
              "      <td>0.011762</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002182</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002947</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001545</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.026186</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014959</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004198</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.048119</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002153</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004999</td>\n",
              "      <td>0.0025</td>\n",
              "      <td>0.007921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.216544</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016696</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.283367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024516</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030130</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.048777</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008809</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.02587</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019374</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023823</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025679</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006085</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.044690</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007734</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010981</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015784</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008869</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         aa        ab   ability     able  ...   µm        μg      μl        μm\n",
              "0  0.019085  0.000000  0.000000  0.00000  ...  0.0  0.000000  0.0000  0.000000\n",
              "1  0.000000  0.000000  0.001572  0.00296  ...  0.0  0.004999  0.0025  0.007921\n",
              "2  0.000000  0.216544  0.000000  0.00000  ...  0.0  0.000000  0.0000  0.000000\n",
              "3  0.000000  0.000000  0.000000  0.00000  ...  0.0  0.000000  0.0000  0.000000\n",
              "4  0.000000  0.000000  0.000000  0.00000  ...  0.0  0.000000  0.0000  0.000000\n",
              "\n",
              "[5 rows x 2000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c47ejTLfBBGb",
        "outputId": "32f1a01a-023a-4b8a-af90-095c63633413"
      },
      "source": [
        "docs_train['vector_tf_idf']=df_tfidf.values.tolist()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8YDDCCUcEXVS",
        "outputId": "bb80314e-fd15-4631-f0d7-8908ce2dbd8b"
      },
      "source": [
        "docs_train.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>context</th>\n",
              "      <th>cleaned_data</th>\n",
              "      <th>vector_tf_idf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>630</td>\n",
              "      <td>Functional Genetic Variants in DC-SIGNR Are As...</td>\n",
              "      <td>functional genetic variant dc-signr associated...</td>\n",
              "      <td>[0.019085058375148987, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>650</td>\n",
              "      <td>Role of S-Palmitoylation on IFITM5 for the Int...</td>\n",
              "      <td>role s-palmitoylation ifitm interaction fkbp o...</td>\n",
              "      <td>[0.0, 0.0, 0.0015718760321186836, 0.0029601433...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1546</td>\n",
              "      <td>First Complete Genome Sequence of a French Bov...</td>\n",
              "      <td>first complete genome sequence french bovine c...</td>\n",
              "      <td>[0.0, 0.21654350686727633, 0.0, 0.0, 0.0, 0.01...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1545</td>\n",
              "      <td>Species‐specific clinical characteristics of h...</td>\n",
              "      <td>species‐specific clinical characteristic human...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.008809309160605168...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>1552</td>\n",
              "      <td>One step closer to an experimental infection s...</td>\n",
              "      <td>one step closer experimental infection system ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.006085110520319744...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    document_id  ...                                      vector_tf_idf\n",
              "0           630  ...  [0.019085058375148987, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
              "11          650  ...  [0.0, 0.0, 0.0015718760321186836, 0.0029601433...\n",
              "22         1546  ...  [0.0, 0.21654350686727633, 0.0, 0.0, 0.0, 0.01...\n",
              "27         1545  ...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.008809309160605168...\n",
              "34         1552  ...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.006085110520319744...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTSYIZuMHkm_"
      },
      "source": [
        "## Sentence Bert Model\n",
        "Pada modul ini, dilakukan embedding dengan model Sentence BERT dengan arsitektur pre-trained bert-base-nli-mean-tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFGZgoJoWl2J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "83e27774769742ba9903fde92eab8ee6",
            "493ee653b01c4e7ba52678b6e9a555e7",
            "6bb6eca63a5947faaf246a7527b31757",
            "c3d22af1d546478b9bcea5a8f40ce093",
            "fbbe1c591fde431e830120344fc8712f",
            "499bd2383e2b491db28f085efc67d267",
            "036ffbccfd09409595f0ee5b8302b68d",
            "d0e6ae66d27947749db16a470965e1d2"
          ]
        },
        "outputId": "562649f6-0100-4c24-dbe7-c8948ff83eb0"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load the BERT model. Various models trained on Natural Language Inference (NLI) https://github.com/UKPLab/sentence-transformers/blob/master/docs/pretrained-models/nli-models.md and \n",
        "# Semantic Textual Similarity are available https://github.com/UKPLab/sentence-transformers/blob/master/docs/pretrained-models/sts-models.md\n",
        "\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83e27774769742ba9903fde92eab8ee6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=405234788.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01lMHwYvLqk8",
        "outputId": "b7ef6a16-5a99-4166-c24d-883a7a10d829"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentenceTransformer(\n",
              "  (0): Transformer(\n",
              "    (auto_model): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (pooler): BertPooler(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (activation): Tanh()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): Pooling()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyI9HINQp7-B"
      },
      "source": [
        "def sentence_embeddings(docs):\n",
        "  sentence_embeddings = model.encode(docs)\n",
        "  return sentence_embeddings"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ_Pp8SeqjhN"
      },
      "source": [
        "x=sentence_embeddings(docs_train['cleaned_data'].to_list())"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T83MJUvWzVum",
        "outputId": "7af8a3cb-dcf0-4d99-ea65-6a4e58cf4bcb"
      },
      "source": [
        "x[0].shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yFCPTisvGyS",
        "outputId": "20209bc9-922e-489c-b4f3-89a6e643852d"
      },
      "source": [
        "y=pd.DataFrame(x)\n",
        "docs_train['vector_bert']=y.values.tolist()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo59IQPrWIXI"
      },
      "source": [
        "## Similarity\n",
        "Kemudian dibuat fungsi similarity untuk kedua kasus, yaitu ranking_ir_bert() dan ranking_ir_tf_idf. Kemudian akan diambil 10 dokumen terbaik berdasarkan similarity terbesar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-nvCFoVNsVG"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHC6uZreNISe"
      },
      "source": [
        "def ranking_ir_bert(query):\n",
        "\n",
        "  query = clean_data(punc_remove(query))\n",
        "\n",
        "  # mengenerate vektor\n",
        "  vector=sentence_embeddings([query])\n",
        "  \n",
        "  # perankingan dokumen dengan cosine similarity\n",
        "  documents=docs_train.copy()\n",
        "  documents['similarity']=documents['vector_bert'].apply(lambda x: cosine_similarity(np.array(vector).reshape(1, -1),np.array(x).reshape(1, -1)).item())\n",
        "  documents.sort_values(by='similarity',ascending=False,inplace=True)\n",
        "  \n",
        "  return documents[['document_id','context','similarity']].head(10).reset_index(drop=True)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_Gq-rQTIIoU"
      },
      "source": [
        "def ranking_ir_tf_idf(query):\n",
        "\n",
        "  query = clean_data(punc_remove(query))\n",
        "\n",
        "  # mengenerate vektor\n",
        "  vector=tfidfvectorizer.transform([query]).toarray()\n",
        "  \n",
        "  # perankingan dokumen dengan cosine similarity\n",
        "  documents=docs_train.copy()\n",
        "  documents['similarity']=documents['vector_tf_idf'].apply(lambda x: cosine_similarity(np.array(vector).reshape(1, -1),np.array(x).reshape(1, -1)).item())\n",
        "  documents.sort_values(by='similarity',ascending=False,inplace=True)\n",
        "  \n",
        "  return documents[['document_id','context','similarity']].head(10).reset_index(drop=True)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "TCH_6XUduE8Q",
        "outputId": "7c300dd5-4a40-4495-c014-9adb98eb1567"
      },
      "source": [
        "ranking_ir_bert('main cause COVID-19')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>context</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1620</td>\n",
              "      <td>A missense mutation in Katnal1 underlies behav...</td>\n",
              "      <td>0.525459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1565</td>\n",
              "      <td>Design, Synthesis, Evaluation and Thermodynami...</td>\n",
              "      <td>0.467449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1561</td>\n",
              "      <td>Acute Hemorrhagic Encephalitis Responding to C...</td>\n",
              "      <td>0.430197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1629</td>\n",
              "      <td>The Intranasal Application of Zanamivir and Ca...</td>\n",
              "      <td>0.427358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1628</td>\n",
              "      <td>Evidence for the Convergence Model: The Emerge...</td>\n",
              "      <td>0.425695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1600</td>\n",
              "      <td>The influenza pandemic preparedness planning t...</td>\n",
              "      <td>0.424730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2683</td>\n",
              "      <td>Estimating the number of infections and the im...</td>\n",
              "      <td>0.423405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>650</td>\n",
              "      <td>Role of S-Palmitoylation on IFITM5 for the Int...</td>\n",
              "      <td>0.422395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1586</td>\n",
              "      <td>In Vitro Bactericidal Activity of 4- and 5-Chl...</td>\n",
              "      <td>0.414151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1632</td>\n",
              "      <td>Metabolic engineering of Escherichia coli into...</td>\n",
              "      <td>0.408922</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   document_id                                            context  similarity\n",
              "0         1620  A missense mutation in Katnal1 underlies behav...    0.525459\n",
              "1         1565  Design, Synthesis, Evaluation and Thermodynami...    0.467449\n",
              "2         1561  Acute Hemorrhagic Encephalitis Responding to C...    0.430197\n",
              "3         1629  The Intranasal Application of Zanamivir and Ca...    0.427358\n",
              "4         1628  Evidence for the Convergence Model: The Emerge...    0.425695\n",
              "5         1600  The influenza pandemic preparedness planning t...    0.424730\n",
              "6         2683  Estimating the number of infections and the im...    0.423405\n",
              "7          650  Role of S-Palmitoylation on IFITM5 for the Int...    0.422395\n",
              "8         1586  In Vitro Bactericidal Activity of 4- and 5-Chl...    0.414151\n",
              "9         1632  Metabolic engineering of Escherichia coli into...    0.408922"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPV_8uYZ2BqB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "b6a2016e-07e9-4b63-b7c1-cd1b29c60113"
      },
      "source": [
        "ranking_ir_tf_idf('main cause COVID-19')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>context</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>185</td>\n",
              "      <td>CDC Summary 21 MAR 2020,\\nhttps://www.cdc.gov/...</td>\n",
              "      <td>0.557419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2450</td>\n",
              "      <td>Safe patient transport for COVID-19\\n\\nhttps:/...</td>\n",
              "      <td>0.363624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>188</td>\n",
              "      <td>The Battle Against Coronavirus Disease 2019 (C...</td>\n",
              "      <td>0.317647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1559</td>\n",
              "      <td>COVID-19 and smoking: A systematic review of t...</td>\n",
              "      <td>0.248786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2522</td>\n",
              "      <td>Identification of COVID-19 Can be Quicker thro...</td>\n",
              "      <td>0.234826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2432</td>\n",
              "      <td>Factors Associated With Mental Health Outcomes...</td>\n",
              "      <td>0.194040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2642</td>\n",
              "      <td>First cases of coronavirus disease 2019 (COVID...</td>\n",
              "      <td>0.159228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2643</td>\n",
              "      <td>Responding to the COVID-19 pandemic in complex...</td>\n",
              "      <td>0.147440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2440</td>\n",
              "      <td>Optimization Method for Forecasting Confirmed ...</td>\n",
              "      <td>0.135337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2683</td>\n",
              "      <td>Estimating the number of infections and the im...</td>\n",
              "      <td>0.129470</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   document_id                                            context  similarity\n",
              "0          185  CDC Summary 21 MAR 2020,\\nhttps://www.cdc.gov/...    0.557419\n",
              "1         2450  Safe patient transport for COVID-19\\n\\nhttps:/...    0.363624\n",
              "2          188  The Battle Against Coronavirus Disease 2019 (C...    0.317647\n",
              "3         1559  COVID-19 and smoking: A systematic review of t...    0.248786\n",
              "4         2522  Identification of COVID-19 Can be Quicker thro...    0.234826\n",
              "5         2432  Factors Associated With Mental Health Outcomes...    0.194040\n",
              "6         2642  First cases of coronavirus disease 2019 (COVID...    0.159228\n",
              "7         2643  Responding to the COVID-19 pandemic in complex...    0.147440\n",
              "8         2440  Optimization Method for Forecasting Confirmed ...    0.135337\n",
              "9         2683  Estimating the number of infections and the im...    0.129470"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4qbFCRdJRRf"
      },
      "source": [
        "## Pengujian dengan Keyword"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUAK2knfNkdd"
      },
      "source": [
        "### Fungsi Keyword \n",
        "Melakukan pengambilan keyword yang digunakan dalam modul Question "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kizrdb_npRLg"
      },
      "source": [
        "def extract_keyword(postag):\n",
        "  keyword = \"\"\n",
        "  for i in range(0,len(postag)):\n",
        "    if postag[i][1]==\"NNP\" or postag[i][1]==\"NNS\" or postag[i][1]==\"NN\" or (postag[i][1]==\"JJ\" and postag[i][0].lower()!=\"many\") or postag[i][1]==\"CD\" or postag[i][1]==\"RBS\" or (postag[i][1]==\"VBN\" and postag[i][1]!=\"been\") or (postag[i][1]==\"VBD\" and postag[i][0].lower()!=\"was\" and postag[i][0].lower()!=\"were\") or postag[i][1]==\"VBG\" or (postag[i][1]==\"VB\" and postag[i][0].lower()!=\"be\") or postag[i][1]==\"RB\":\n",
        "      keyword += postag[i][0] +\" \"\n",
        "  if len(keyword)!=0 and keyword[len(keyword)-1] == \" \":\n",
        "    keyword = keyword[:-1]\n",
        "  return keyword"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mqwam11rcyH"
      },
      "source": [
        "def question_type_extraction(question):\n",
        "  qarray = [0,0,0,0,0,0,0,0,0]\n",
        "  labq = [\"What\",\"Where\",\"Why\",\"Who\",\"When\",\"How much\",\"How many\",\"Which\",\"How\"]\n",
        "  qtype = \"\"\n",
        "  what = 0\n",
        "  where = 1\n",
        "  why = 2\n",
        "  who = 3\n",
        "  when = 4\n",
        "  howmuch = 5\n",
        "  howmany = 6\n",
        "  which = 7\n",
        "  how = 8\n",
        "\n",
        "  for i in range(0,len(question)):\n",
        "    if question[i].lower() == \"what\":\n",
        "      qarray[what] = 1\n",
        "    elif question[i].lower() == \"where\":\n",
        "      qarray[where] = 1\n",
        "    elif question[i].lower() == \"why\":\n",
        "      qarray[why] = 1\n",
        "    elif question[i].lower() == \"who\":\n",
        "      qarray[who] = 1\n",
        "    elif question[i].lower() == \"when\":\n",
        "      qarray[when] = 1\n",
        "    elif question[i].lower() == \"which\":\n",
        "      qarray[which] = 1\n",
        "    elif question[i].lower() == \"how\":\n",
        "      if question[i+1].lower() != \"much\" and question[i+1].lower() != \"many\":\n",
        "        qarray[how] = 1\n",
        "      elif question[i+1].lower() == \"much\":\n",
        "        qarray[howmuch] = 1\n",
        "      elif question[i+1].lower() == \"many\":\n",
        "        qarray[howmany] = 1\n",
        "\n",
        "  \n",
        "  if 1 in qarray:\n",
        "    for i in range(0,len(qarray)):\n",
        "      if qarray[i]==1:\n",
        "        qtype += labq[i] + \",\"\n",
        "  else:\n",
        "    qtype=\"Unknown\"\n",
        "\n",
        "  if qtype[len(qtype)-1] == \",\":\n",
        "    qtype = qtype[:-1]\n",
        "  return qtype"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzRxxdC7pZzZ"
      },
      "source": [
        " def question_understanding(dataset):\n",
        "  keywords = []\n",
        "  qtype = []\n",
        "  answer = []\n",
        "\n",
        "  for i in range(0,len(dataset)):\n",
        "    sentence = pos_tag(word_tokenize(dataset.question[i]))\n",
        "    keywords.append(extract_keyword(sentence))\n",
        "    qtype.append(question_type_extraction(word_tokenize(dataset.question[i])))\n",
        "    ans = dataset.answers_text[i]\n",
        "    answer.append(ans)\n",
        "  \n",
        "  output = pd.DataFrame({\"keywords\":np.array(keywords),\n",
        "                         \"question_type\":np.array(qtype),\n",
        "                         \"answer\":np.array(answer)})\n",
        "\n",
        "  return output"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jI3P2kFNn3A"
      },
      "source": [
        "### Evaluasi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvHH9_PIatzO"
      },
      "source": [
        "#### TF IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzsTl4HUpnu7"
      },
      "source": [
        "qu = question_understanding(new_data)\n",
        "qu['docs_id']=new_data['document_id']"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykbTEKvpJTKH"
      },
      "source": [
        "qu['docs_recc']=qu['keywords'].apply(lambda x : ranking_ir_tf_idf(x))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSW9nHn4C9u_"
      },
      "source": [
        "Pada evaluasi ini, dilakukan pengecekan pada masing-masing apakah dokumen dari keyword tersebut termasuk ke dalam 10 dokumen terbaik yang didapat dari keyword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5b42ihaRxGu"
      },
      "source": [
        "is_docs_there=[]\n",
        "for idx,item in qu.iterrows():\n",
        "  is_docs_there.append(item['docs_id'] in qu['docs_recc'][idx]['document_id'].unique())"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyrWsGlzZHoR",
        "outputId": "f86c9045-3745-4dcb-dc34-b78069cc0d3e"
      },
      "source": [
        "qu['is_found']=is_docs_there\n",
        "print(qu['is_found'].sum()/2019)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6988608221892025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4z48-fdcn54"
      },
      "source": [
        "Berdasarkan hasil evaluasi, dari 2019 pertanyaan, 69% pertanyaan berhasil mendapatkan dokumen yang sesuai berdasarkan 10 dokumen yang diambil sebelumnya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX4b8YtNax5h"
      },
      "source": [
        "#### BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGr8Hz38ay2f"
      },
      "source": [
        "qu = question_understanding(new_data)\n",
        "qu['docs_id']=new_data['document_id']"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a282g5pWa5eF"
      },
      "source": [
        "qu['docs_recc']=qu['keywords'].apply(lambda x : ranking_ir_bert(x))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36nRglvzcXtM"
      },
      "source": [
        "Pada evaluasi ini, dilakukan pengecekan pada masing-masing apakah dokumen dari keyword tersebut termasuk ke dalam 10 dokumen terbaik yang didapat dari keyword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQAG_hvtbXN3"
      },
      "source": [
        "is_docs_there=[]\n",
        "for idx,item in qu.iterrows():\n",
        "  is_docs_there.append(item['docs_id'] in qu['docs_recc'][idx]['document_id'].unique())"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3MTcEShbdhy",
        "outputId": "13b34154-8cfb-4bf7-a7ef-bc3f7d56f3fe"
      },
      "source": [
        "qu['is_found']=is_docs_there\n",
        "print(qu['is_found'].sum()/2019)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2555720653789004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaplDqA5dS1e"
      },
      "source": [
        "Berdasarkan hasil evaluasi, dari 2019 pertanyaan, 25% pertanyaan berhasil mendapatkan dokumen yang sesuai berdasarkan 10 dokumen yang diambil sebelumnya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWuS6Xjd6xuy"
      },
      "source": [
        "#### Keyword yang tidak jelas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "259cGMUwEO6P"
      },
      "source": [
        "Pada dataset terdapat keyword yang tidak jelas seperti pada cell dibawah ini, sehingga dokumen yang di retrieve tidak benar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "ckkgdtsh3QFE",
        "outputId": "f0bb92a2-39ae-4480-d7c5-fd03ae5a8a92"
      },
      "source": [
        "qu.tail(1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keywords</th>\n",
              "      <th>question_type</th>\n",
              "      <th>answer</th>\n",
              "      <th>docs_id</th>\n",
              "      <th>docs_recc</th>\n",
              "      <th>is_found</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2018</th>\n",
              "      <td>arrows indicate Figure 1</td>\n",
              "      <td>What</td>\n",
              "      <td>infectious transmission pathways between hosts</td>\n",
              "      <td>1713</td>\n",
              "      <td>document_id                                ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      keywords  ... is_found\n",
              "2018  arrows indicate Figure 1  ...    False\n",
              "\n",
              "[1 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "py17p_iE3TLE",
        "outputId": "415c079a-5eb8-4c43-ce8c-0154ecd68612"
      },
      "source": [
        "ranking_ir_tf_idf(qu.keywords[2018])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>context</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2683</td>\n",
              "      <td>Estimating the number of infections and the im...</td>\n",
              "      <td>0.064803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2519</td>\n",
              "      <td>Detectable 2019-nCoV viral RNA in blood is a s...</td>\n",
              "      <td>0.064411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>186</td>\n",
              "      <td>Identifying Locations with Possible Undetected...</td>\n",
              "      <td>0.061561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1621</td>\n",
              "      <td>Vesicular stomatitis virus with the rabies vir...</td>\n",
              "      <td>0.051927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1576</td>\n",
              "      <td>Characterization of a New Member of Alphacoron...</td>\n",
              "      <td>0.051283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1698</td>\n",
              "      <td>Accelerated viral dynamics in bat cell lines, ...</td>\n",
              "      <td>0.049541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1662</td>\n",
              "      <td>The Evolutionary Dynamics of the Lion Panthera...</td>\n",
              "      <td>0.049041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1596</td>\n",
              "      <td>Glycyrrhizin Exerts Antioxidative Effects in H...</td>\n",
              "      <td>0.047571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1620</td>\n",
              "      <td>A missense mutation in Katnal1 underlies behav...</td>\n",
              "      <td>0.047453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1585</td>\n",
              "      <td>Immunomodulatory Activity and Protective Effec...</td>\n",
              "      <td>0.042563</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   document_id                                            context  similarity\n",
              "0         2683  Estimating the number of infections and the im...    0.064803\n",
              "1         2519  Detectable 2019-nCoV viral RNA in blood is a s...    0.064411\n",
              "2          186  Identifying Locations with Possible Undetected...    0.061561\n",
              "3         1621  Vesicular stomatitis virus with the rabies vir...    0.051927\n",
              "4         1576  Characterization of a New Member of Alphacoron...    0.051283\n",
              "5         1698  Accelerated viral dynamics in bat cell lines, ...    0.049541\n",
              "6         1662  The Evolutionary Dynamics of the Lion Panthera...    0.049041\n",
              "7         1596  Glycyrrhizin Exerts Antioxidative Effects in H...    0.047571\n",
              "8         1620  A missense mutation in Katnal1 underlies behav...    0.047453\n",
              "9         1585  Immunomodulatory Activity and Protective Effec...    0.042563"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfholHmXLgkx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}